# Sparkify Startup Project
This project is aimed at creation of a Postgres database that will be used for analytical purposes for a startup company called Sparkify.
The project itself is a new music streaming app that has got quite a few users.
At the moment the company has got only json logs related to the users activity generated by the Sparkify app. 
However they would like to have solid analytics built on this basis

## Project Purpose
<ul>
<li>Create a database schema</li>
<li>Create an ETL pipeline</li>
<li>Test newly created database with the analytics team queries</li>
</ul>


## Database Schema
The current database schema uses the two json logs files, such as `log_data` and `song_data`.
They are present in the root inside the folder `data`.

The final Postgres database includes four dimensional and one fact tables, the description of which is present below.</b>

**Dimensional Tables**

`USERS`</br>
This table represents the Sparkify app users, below there is an example of 1 line of this table.
| user_id | first_name | last_name | gender | level |
|--------:|-----------:|----------:|-------:|------:|
|      91 |     Jayden |      Bell |      M |  free |

`SONGS`</br>
This table represents the songs available in the Sparkify music db, below there is an example of 1 line of this table.
|            song_id | title |          artist_id | year |  duration |
|-------------------:|------:|-------------------:|-----:|----------:|
| SOMZWCG12A8C13C480 |  None | ARD7TVE1187B99BFB1 |    0 | 218.93179 |

`ARTISTS`</br>
This table represents the artists available in the Sparkify music db, below there is an example of 1 line of this table.
|          artist_id | artist_name | artist_location | artist_latitude | artist_longitude |
|-------------------:|------------:|----------------:|----------------:|-----------------:|
| ARD7TVE1187B99BFB1 |      Casual | California - LA |             NaN |              NaN |

`TIME`</br>
This table represents the timestamps of records in songplays broken down into specific units, below there is an example of 1 line of this table.
| start_time | hour | day | week | month | year | weekday |
|-----------:|-----:|----:|-----:|------:|-----:|--------:|
|    0:25:44 |    0 |   1 |    1 |     1 | 1970 |       3 |

**Fact Tables**

`SONGPLAYS`</br>
This table represent the records in log data associated with song plays i.e. records with page NextSong, below there is an example of 1 line of this table.
| songplay_id |         start_time | user_id | level |            song_id |          artist_id | session_id |                        location |                                                              user_agent |
|------------:|-------------------:|--------:|------:|-------------------:|-------------------:|-----------:|--------------------------------:|------------------------------------------------------------------------:|
|           0 | 1970-01-01 0:25:44 |      91 |  free | SOMZWCG12A8C13C480 | ARD7TVE1187B99BFB1 |        829 | Dallas-Fort Worth-Arlington, TX | Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0) |

## ETL Pipeline
ELT pipeline is represented by `etl.py` file located in the root folder of the project.</br>
This file is responsible for processing both songs and logs files in json format and creation of both dimensional and fact tables afterwards.</br>
The file `create_tables.py` should be run before running `etl.py` file as it is the file that initiates the creation of an empty Postgres db.</br>
This file `sql_queries.py` is used by both `create_tables.py` and `etl.py` and contains the sql queries for both creation of tables for the Postgres db and further insert of
the data from the log files.</br>
After `create_tables.py` and `etl.py` files have been sucessfully run via terminal, it is worth double checking that the whole process was run successfully via `test.ipynb` file.</br>
If everything went as expected, the `test.ipynb` will run without any issues and one should see the head lines of each table that was created.</br>

